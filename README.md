# Adventures in Autograding

## A Scenario

For the sake of building a narrative, let's say Student X is ready to get started on a 1502 drill.

1. They log into Blackboard, go to the list of available drill links, and click on the desired one.
   - **result**: a GitHub repo containing a copy of the starting code for the drill is created by GitHub Classroom and the student is given non-admin access to this repo.
1. The student clones the repo to their own machine. Perhaps because they're not quite comfortable with Git commands yet, they decide to download a zip file and unzip it into a convenient location.
   - **result**: the student now has a folder containing all the folders and files they need to start working.
1. The student uses the Import command in Eclipse with the downloaded folder.
   - **result**: Eclipse uses the various files and folders in the repo to create a working Eclipse project. The project uses the configuration files in the repo to initialize any necessary Eclipse plugins.
1. The student begins coding a solution (after thinking long and carefully about the problem first, naturally).
   - **result**: as the student saves their work, the Infinitest Eclipse plugin gives them immediate feedback about whether the unit tests provided with the project are passing or failing. Also, static code analysis tools like Checkstyle and PMD display any issues after every source file save.
1. The student continues working on the drill, with the aim of making all the tests pass and all the analysis tools happy. Eventually, they get to that point and are ready to submit their work. Because they're still not comfortable with Git commands, they decide to log into GitHub, go to their drill repo page, and drag and drop the src folder from their project in Eclipse into the GitHub page, remembering to commit their work.
   - **result**: upon hitting the commit button, a GitHub action is triggered. This action runs a build, which includes compiling the code, running the same static code tools as were used in Eclipse, and running the unit tests in the project. A summary report with a standardized format of the results is generated. This whole process takes less than a minute.
1. When the due date arrives, the instructor uses the GitHub Classroom Assistant to download all the submissions for the drill. They then use the results in the summary reports to assign marks for the drill. As drills are likely a pass/fail affair, this is a particularly easy task.

## What's the Catch?

Obviously, this is not a free lunch. What work does an instructor have to do to make all this happen?

### **Create an Assessment That's Autogradable!**

- if you want to automate marking, you have to create assessments that can be tested easily. This typically means moving to assessments whose functionality can be tested with an automated tool; the easiest tool to reach for here is JUnit.
- this can be a challenging step; although you _can_ test with console input/output in JUnit, it's not ideal and can require a lot of regex work, which is not the most pleasant thing in the world. But once you start gaining experience using testing tools, this step becomes significantly easier...and dare I say...fun?

### **Write JUnit Tests**

- the current summarizer tool that I've made only recognizes reports generated by JUnit 5...but it's the standard these days and has many useful features that aren't available in JUnit 4, so one should be using 5 anyway.
- there are some libraries available that make testing console input/output straightforward, so that kind of testing is available if you want it.
- since tests are the primary form of feedback for students, they have to be well-written and their failure messages should be clear and unambiguous. Ideally, your tests should be self-documenting, as students in later programming courses should be urged to read the tests as a source of documentation!

### **Create Settings Files for Tools**

- each static analysis tool needs a settings file that contains the rules to be enforced by the tool. These tools tend to be a bit overboard for new programmers, so it's important to create a fairly relaxed set of rules. Setting up the rules "just so" can be a tad time-consuming, but fortunately, once done, the settings can be re-used for all iterations of a course...at least until the tool providers change the format of the settings files, or deprecates certain rules! :)
- it's important to choose tools that are available as **both** a command-line tool (for the build process) **and** Eclipse plugin (for everyday coding). If this isn't the case, then a student will be frustrated if their IDE says everything is fine, but then the build fails. I'm currently suggesting PMD (for "best practice" checks) and Checkstyle (for style checks) as they both fit the bill.

### **Convert Summary Reports to Marks**

- this is where things get interesting: you need to figure out how to map your summary results to final grades. For a pass/fail assessment, this might be stunningly easy - if there are **any** errors in compilation, static analysis, or unit tests, you fail - otherwise, you pass.
- but what if it's not a pass/fail situation? How do you weight the results of the static analysis? How do you weight the tests? Are some worth more than others? If so, by how much?
- and the fun doesn't stop there: even after you've decided the weightings of the results, how do you parse the summary report to generate the marks? I'm currently leaving that up to the reader - the summary reports have a very specific format, so creating a little tool that maps a text file to actual results shouldn't be overly onerous - but it's not a walk in the park either.
  > NOTE: if you're loathe to take the plunge on this step, be aware that there are some resources out there already that automate this "assigning points to tests/tools" process. I've worked with [gradlegrader](https://github.com/cs125-illinois/gradlegrader) and (RiceChecks)[https://github.com/RiceComp215-Staff/RiceChecks]. They both require Gradle to work, which is both a bane and a boon. They also are quite configurable...but that's a double-edged sword as well, right? In any case, if you want to talk about these tools, let's do it.
